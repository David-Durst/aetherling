=============================================
=============================================
SpaceTime Functions
=============================================
=============================================

Notation and definitions:

f :: {a, S} -> {b, T}

The above signature declares that a firing of the hardware module
f requires 'a' input tokens of type S to produce 'b' tokens of type T.

area: area of the hardware module

Time: It would be simplest to state that time() is the time between
the first token arriving for an output and the output going
out. However rate increasing operators like up() and partition() have
time proportional to waiting on generating outputs, not time
proportional to waiting on inputs to arrive.


Parallel Versions:
============================================

# also referred to as repeat k or broadcast k
up_x k :: {1,T} -> {1,T[k]} 
   area(up_x k) = k
   time(up_x k) = 1

# also referred to as select k i (down_x is a special case where i is 0)
down_x k :: {1,T[k]} -> {1,T} 
   area(down_x k) = k
   time(down_x k) = 1

# generalized shift
shift_x k s :: {1,T[s]} -> {1,T[k]} 
   area(shift k s) = k
   time(shift k s) = s

Example: shift_x 5 3 receives:
[0 1 2 3 4]
[5 6 7 8 9]
[10 11 12 13 14]... 
and outputs:
[0 1 2 3 4]
[3 4 5 6 7]
[6 7 8 9 10]

For syntactic sugar, I'll write: shift_x k = shift_x k 1

stencil_x k n :: {1,T[n]} -> {1,T[n-k+1][k]}
   area(stencil_x k n) = k*n
   time(stencil_x k n) = 1
   
fold_x k f u :: {1,S[k]} -> {1,T}
   area(fold_x k f) = k*area(f)
   time(fold_x k f) = time(f)

map_x k f :: {1,S[k]} -> {1,T[k]}
   area(map_x k f) = k*area(f)
   time(map_x k f) = time(f)

# NOTE(kayvonf): the above definition assumes f :: {1,S} -> {1,T}.  I do not yet know how to handle a multi-rate f in a parallel map. It feels like the answer is a module with the signature: f :: {1,S} -> {k,T}.

# reinterpret 1D array as 2D array
# zero cost since it's just a type reinterpretation
arr_partition k i :: {1,T[k]} -> {1,T[k/i][i]}
   area(arr_partition k i) = 0
   time(arr_partition k i) = 0

# reinterpret 2D array as 1D array
# zero cost since it's just a type reinterpretation
arr_flatten k i :: {1,T[k][i]} -> {1,T[k*i]}
   area(arr_flatten k i) = 0
   time(arr_flatten k i) = 0

   
Sequential Versions:
============================================

up_t n k :: {1,T} -> {k,T}  
   area(up_t k) = 1
   time(up_t k) = k

down_t n k :: {k,T} -> {1,T} 
   area(down_t k) = 1
   time(down_t k) = k

shift_t n k s :: {s,T} -> {k,T} 
   area(shift k s) = k
   time(shift k s) = s

Example: 
Given input stream of 0 1 2 3 4 5 6 7 8 9 10...
shift_t 5 3 outputs: 0 1 2 3 4   3 4 5 6 7   6 7 8 9 10 ...

For syntactic sugar, I'll write shift_t k = shift_t k 1 

fold_t n f id :: {k,S} -> {1,T}
   area(fold_t n f) = area(f)
   time(fold_t n f) = k * time(f)

map_t n f :: {1,S} -> {1,T)
   area(map_t n f) = area(f)
   time(map_t n f) = time(f)

# NOTE(kayvonf): The above definition assumes f :: {1,S} - > {1,T}.  It's not 100% clear to me what the semantics of a multi-rate f should be.  I believe, the resulting stream is a concatenation of the streamed outputs of f?
   
Partition/Flatten Operators: 
============================================

Notes: these operators do not have distinct _x and _t versions since they convert between the stream and array forms (convert data in space into data in time and vice versa).

# partition large array token into i smaller array tokens. Partition increases rate.
partition i :: {1,T[i*j]} -> {i,T[j]}
   area(partition i) = i*j 
   time(partition i) = i
   
# aggregate i tokens into a single large token. Flatten decreased rate.
flatten i :: {i,T[j]} -> {1,T[i*j]}
   area(flatten i) = i*j
   time(flatten i) = i


=============================================
=============================================
Useful theorems:
=============================================
=============================================


Relationship between up and down, up_t/up_x, and down_t/down_x
=============================================

up_t k $ down_t k = id
down_t k $ up_t k = id

up_t k = partition k $ up_x k
up_x k = flatten k $ up_t k

down_t k = down_x k $ partition k 
down_x k = down_t k $ flatten k 

Relationship between shift_x and shift_t:
=============================================
(note asymmetry of flatten and partition arguments)

shift_x n k s = flatten k $ shift_t n k s $ partition s
shift_t n k s = partition k $ shift_x n k s $ flatten s

Stencil identities: 
=============================================

# when the stencil is the entire array, nothing happens
stencil_x k k = id

Stencil / Shift throughput changing theorems:
=============================================

# fully parallel stencil to p-parallel stencil
# aka: how to "slow down" a fully parallel stencil to a partially parallel one
# FIXME(kayvonf): as defined below, this emits a output T[n] not T[n-k+1]. In practice the last p+k-1-pixel tile emitted by shift_x is not completely full. (This would also be true is p does not evenly divide n) 
stencil_x n k = flatten n/p $ map_t n/p (stencil_x p+k-1 k) $ (shift_x n/p p+k-1 p) $ partition n/p

In the special case where p=1, after invoking the map_t and stencil_x identity theorems, then
it's just a fully sequential shift
# NOTE(kayvonf): careful handling of boundary conditions is needed to get this result from the general case
stencil_x n k = flatten n-k+1 $ shift_x n k 1 $ partition n

# fully sequential shift to p-parallel stencil
shift_x k 1 = partition p $ map_t n/p (stencil_x p+k-1 k) $ (shift_x n/p p+k-1 p) $ flatten p 

In the special case where p=N, then it's just a fully parallel stencil
# NOTE(kayvonf): careful handling of boundary conditions is needed to get this result from the general case
shift_x k 1 = partition n-k+1 $ stencil_x n k $ flatten n 


Map identity theorem:
=============================================

# mapping the identity function onto an array or stream leaves the input unchanged
map_x n id = id
map_t n id = id 

# mapping onto a array or stream size of 1 is just operating on a singleton
map_x 1 f  = f
map_t 1 f  = f

Map fusion theorem:
=============================================
(true for _t and _x versions of map)

# can use consecutive maps into a single map
map (f.g) = map f $ map g

Map/up/down reorder theorem:
(true for _t and _x versions of map)
=============================================

# (these are not specific to _t or _x versions)

map (down k) $ map f = map f $ map (down k)
map f $ map (up k) = map (up k) $ map f 

Map/fold fusion theorem:
=============================================
(true for _t and _x versions of map/fold)

f :: (S,T) -> T
g :: U -> S 

f2 x y = f g(x) y :: (U, T) -> T 

# Can fuse a map followed by a fold into a single fold
fold f id $ map g = fold f2 id

Map throughput-changing theorem:
=============================================

# fully parallel map to a partially parallel map with parallelism p
# aka: how to "slow down" a fully parallel map to a partially parallel one
map_x k f = flatten k/p $ map_t k/p (map_x p f) $ partition k/p 

In the special case where p=1, then it's a fully serial map
map_x k f = partition k $ map_t k f $ flatten k

# fully sequential map to a partially parallel map with parallelism p 
map_t k f = partition p $ map_t k/p (map_x p f) $ flatten p

In the special case where p=k, then it's a fully parallel map
map_t k f = partition k $ map_x k f $ flatten k  


Fold throughput-changing theorem:
=============================================

TBD


Partition/flatten identity theorem:
=============================================

partition k $ flatten k = id
flatten k $ partition k = id



