SpaceTime Functions

up_x k :: {1,T} -> {1,T[k]} # also referred to as repeat k or broadcast k
   area(up_x k) = k
   time(up_x k) = 1

down_x k :: {1,T[k]} -> {1,T} # also referred to as select k i 
   area(down_x k) = k
   time(down_x k) = 1

stencil_x k n :: {1,T[n]} -> {1,T[n-k][k]}
   area(stencil k) = k*n
   time(down_x k) = 1

fold_x k f id :: {1,S[k]} -> {1,T}
   area(fold_x k f) = k*area(f)
   time(fold_x k f) = time(f)

map_x k f :: {1,S[k]} -> {1,T[k]}
   area(map_x k f) = k*area(f)
   time(map_x k f) = time(f)


up_t k :: {1,T} -> {k,T}  
   area(up_t k) = 1
   time(up_t k) = k

down_t k :: {k,T} -> {1,T} 
   area(down_t k) = 1
   time(down_t k) = k

# stencil = shift
shift k :: {1,T} -> {1,T[k]} 
   area(shift k) = k
   time(shift k) = k

Notes: shift gives k elements, with 1 at a time increment in index
   
fold_t k f id :: {k,S} -> {1,T}
   area(fold_t k f) = area(f)
   time(fold_t k f) = k * time(f)

map_t f :: {1,S} -> {1,T)
   area(map_t f) = area(f)
   time(map_t f) = time(f)
 
partition i :: {1,T[i*j]} -> {i,T[j]}
   area(partition i) = i*j 
   time(partition i) = i

Notes: partition splits into disjoint groups of i elements that are
emitted sequentially.  Partition increases rate.
   
flatten i :: {i,T[j]} -> {1,T[i*j]}
   area(flatten i) = i*j
   time(flatten i) = i

Notes: flatten takes a stream of elements and squished them together
       into a stream of larger elements emitted at a lower
       rate. (Flatten decreases rate)
   
verbal defintion of convolution: given a stream of arrays of length n and type S, convert them into arrays of length n of type T, where T is constructed by applying f to the elements i, i-1, ..., i-k of the input stream.
convolution in time:
conv_t n k f id :: int -> int -> ((S,T) -> T) -> {n, S} -> {n, T}
conv_t n k f = fold_t k f id $ shift k
area(conv_t n k f id) = area(f)
time(conv_t n k f id) = n * time(k*f)

convolution fully parallel in space:
conv_x n k f id :: int -> int -> ((S,T) -> T) -> {1, S[n]} -> {1, T[n]}
conv_x n k f = map_x (n-k) (fold_x k f id) $ stencil_x k n
area(conv_x n k f id) = n*k*(1+area(f))
time(conv_f n k f id) = time(f)

I gave conv_t and conv_x different type signatures in how they take their input arrays due to their different ways of taking in parallelism. conv_t is parallel in time, so it takes its array in over n ticks. I don't think that conv_t should take the entire array in as input in one tick as that would require O(n) area to store it all while it is processed. Am I wrong?


a_x is arbitrarily parallel, this one takes in whole array at start
conv_a_x n k p f id :: int -> int -> int -> ((S,T) -> T) -> {1, S[n]} -> {p, T[n/p]}
conv_a_x n k p f id = map_x ((n/p)-k) (fold_x k f id) k $ partition p $ stencil_x k n

conv_a_x n k p f id = partition $ (this is actually not neccesary, the parittion can handle the array of arrays of length n just fine, still split them into p pieces - need somehting here to convert the stencil collection of arrays into one big array, so partition can split up the arrays and feed them out one tick at a time) $ stencil_x k n

why is it important to be able to transform between them if I can just get arbtrary parallelism directly? Should I read the thesis to get that?





